{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a5305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cvxopt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first experiment about the offline QP\n",
    "class Submodular_QP:\n",
    "    noise=None\n",
    "#we use the Submodular_QP.constraint to record the constraint matrix A, i.e., Ax\\\\\\\\le b\\n\",\n",
    "    constraints=None\n",
    "# we take QP as f(x)=1/2x^{T}Hx+h^{T}x\\\n",
    "    def __init__(self):\n",
    "        self.H=None\n",
    "        self.h=None\n",
    "    def generate(self,n):\n",
    "    # n is the dimension of x=(x_{1},...,x_{n})\n",
    "        self.H=np.random.rand(n,n)\n",
    "        self.H=0.5*(self.H+self.H.T)\n",
    "        self.H=-self.H\n",
    "        self.h=-self.H.dot(np.ones((n,1)))\n",
    "    def stochastic_gradient_oracle(self,x):\n",
    "        # return a stochastic gradient g=\\\\\\\\nable f(x)+\\\\\\\\deta*U[-1,1] for E(g)=\\\\\\\\nable f(x)=Hx+h\\\\n\\\",\\n\",\n",
    "        noise=Submodular_QP.noise*np.random.randn(self.H.shape[0],1)\n",
    "        return self.H.dot(x)+self.h+noise\n",
    "    def stochastic_boosting_gradient_oracle(self,x):\n",
    "        # we first generate a z~Z where Pr(Z\\\\\\\\le z)=(exp(z-1)-exp(-1))/(1-exp(-1))\\\\n\\\",\\n\",\n",
    "        z=math.log((1-math.exp(-1))*np.random.rand()+math.exp(-1))+1\n",
    "        return (1-math.exp(-1))*self.stochastic_gradient_oracle(z*x)\n",
    "    def exact_value_oracle(self,x):\n",
    "        # return f(x)\n",
    "        return float(0.5*x.T.dot(self.H.dot(x))+self.h.T.dot(x))\n",
    "    def set_constraints(m,n):\n",
    "        Submodular_QP.constraints=np.random.rand(m,n)\n",
    "    def set_noise(delta):\n",
    "        Submodular_QP.noise=delta\n",
    "    def set_delay(self,num):\n",
    "        self.delay=np.random.randint(1,num+1)\n",
    "        \n",
    "        \n",
    "#first method: traditional gradient ascent\n",
    "def projected_gradient_ascent(H,T=500,batch=1):\n",
    "    np.random.seed(T)\n",
    "    m=Submodular_QP.constraints.shape[0]\n",
    "    n=Submodular_QP.constraints.shape[1]\n",
    "    outcome=[0]*T\n",
    "    point=np.zeros((n,1))\n",
    "    #setting the projection QP as 1/2x^{T}Px+q^{T}x s.t Gx \\\\\\\\le g, Cx=c\\\\n\\\",\\n\",\n",
    "    G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "    g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "    P=cvxopt.matrix(2*np.eye(n))\n",
    "    for i in range(T):\n",
    "        gradient=sum(H.stochastic_gradient_oracle(point) for j in range(batch))/batch\n",
    "        point+=gradient/math.sqrt(i+1)\n",
    "        q=cvxopt.matrix(-2*point)\n",
    "        sol=cvxopt.solvers.qp(P,q,G,g)\n",
    "        point=np.array(sol['x'])\n",
    "        point=point.reshape(n,1)\n",
    "        outcome[i]=H.exact_value_oracle(point)\n",
    "    return outcome\n",
    "#second method: boosting gradient ascent\n",
    "def boosting_gradient_ascent(H,T=500,batch=1):\n",
    "    np.random.seed(T)\n",
    "    m=Submodular_QP.constraints.shape[0]\n",
    "    n=Submodular_QP.constraints.shape[1]\n",
    "    outcome=[0]*T\n",
    "    point=np.zeros((n,1))\n",
    "    #setting the projection QP as 1/2x^{T}Px+q^{T}x s.t Gx \\\\\\\\le g, Cx=c\\\n",
    "    G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "    g=cvxopt.matrix(np.concatenate((np.ones((m+n,1)),np.zeros((n,1))),axis=0))\n",
    "    P=cvxopt.matrix(2*np.eye(n))\n",
    "    for i in range(T):\n",
    "        gradient=sum(H.stochastic_boosting_gradient_oracle(point) for j in range(batch))/batch\n",
    "        point+=gradient/math.sqrt(i+1)\n",
    "        q=cvxopt.matrix(-2*point)\n",
    "        sol=cvxopt.solvers.qp(P,q,G,g)\n",
    "        point=np.array(sol['x'])\n",
    "        point=point.reshape(n,1)\n",
    "        outcome[i]=H.exact_value_oracle(point)\n",
    "    return outcome\n",
    "#the third method:conditional gradient ascent\n",
    "def continuous_greedy_method(H,T=500):\n",
    "    np.random.seed(T)\n",
    "    m=Submodular_QP.constraints.shape[0]\n",
    "    n=Submodular_QP.constraints.shape[1]\n",
    "    outcome=[0]*T\n",
    "    point=np.zeros((n,1))\n",
    "    G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "    g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "    for i in range(T):\n",
    "        gradient=H.stochastic_gradient_oracle(point)\n",
    "        sol=cvxopt.solvers.lp(cvxopt.matrix(-gradient),G,g)\n",
    "        point=point+np.array(sol['x'])/T\n",
    "        outcome[i]=H.exact_value_oracle(point)\n",
    "    return outcome\n",
    "#the fouth method: SCG\n",
    "def stochastic_greedy_method(H,T=500):\n",
    "    np.random.seed(T)\n",
    "    m=Submodular_QP.constraints.shape[0]\n",
    "    n=Submodular_QP.constraints.shape[1]\n",
    "    outcome=[0]*T\n",
    "    point=np.zeros((n,1))\n",
    "    G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "    g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "    gradient=H.stochastic_gradient_oracle(point)\n",
    "    for i in range(T):\n",
    "        rho=2/((i+4)**(2/3))\n",
    "        gradient=(1-rho)*gradient+rho*H.stochastic_gradient_oracle(point)\n",
    "        sol=cvxopt.solvers.lp(cvxopt.matrix(-gradient),G,g)\n",
    "        point=point+np.array(sol['x'])/T\n",
    "        outcome[i]=H.exact_value_oracle(point)\n",
    "    return outcome\n",
    "#the final method:SCG++\n",
    "def stochastic_greedy_pp(H,T=500):\n",
    "        np.random.seed(T)\n",
    "        m=Submodular_QP.constraints.shape[0]\n",
    "        n=Submodular_QP.constraints.shape[1]\n",
    "        outcome=[0]*T\n",
    "        point=np.zeros((n,1))\n",
    "        G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "        g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "        g_t=sum(H.stochastic_gradient_oracle(point) for j in range(100**2))/(100**2)\n",
    "        for i in range(T):\n",
    "            gradient=cvxopt.matrix(-g_t)\n",
    "            sol=cvxopt.solvers.lp(gradient,G,g)\n",
    "            point1=np.array(sol['x'])/T\n",
    "            point=point+point1\n",
    "            outcome[i]=H.exact_value_oracle(point)\n",
    "            g_t=g_t+H.H.dot(point1)\n",
    "            #print(H.H.dot(point1))       \n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016eb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second experiment: the online submodular QP\n",
    "#before going into the detail of the algorithms,\n",
    "#we want to realize a priority queue to record the information of delays.\n",
    "class node:\n",
    "    def __init__(self,delay=None,gradient=None):\n",
    "        # we use the self.delay to record the delay term of self.gradient\\n\",\n",
    "        self.delay=delay\n",
    "        self.gradient=gradient\n",
    "class Priority:\n",
    "    def __init__(self):\n",
    "        self.data=[]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def insert(self,delay=None,gradient=None):\n",
    "        self.data.append(node(delay,gradient))\n",
    "        if len(self)==1:\n",
    "            pass\n",
    "        else:\n",
    "            child=len(self)\n",
    "            father=child//2\n",
    "            while self.data[father-1].delay>self.data[child-1].delay:\n",
    "                self.data[father-1],self.data[child-1]=self.data[child-1],self.data[father-1]\n",
    "                child=father\n",
    "                father=child//2\n",
    "                if child==1:\n",
    "                    break\n",
    "    def show(self):\n",
    "        return self.data[0]\n",
    "    def minus_one(self):\n",
    "        for i in range(len(self.data)):\n",
    "            self.data[i].delay-=1\n",
    "    def pop(self):\n",
    "        data=self.data[0]\n",
    "        if len(self)==1:\n",
    "            self.data=[]\n",
    "        else:\n",
    "            self.data[0]=self.data.pop()\n",
    "            father=1\n",
    "            child=father*2\n",
    "            setting=True\n",
    "            while setting:\n",
    "                if child<=len(self.data):\n",
    "                    mini_child=child\n",
    "                    if child+1<=len(self.data):\n",
    "                        if self.data[mini_child-1].delay>self.data[child].delay:\n",
    "                            mini_child=child+1\n",
    "                    if self.data[father-1].delay>self.data[mini_child-1].delay:\n",
    "                        self.data[father-1],self.data[mini_child-1]=self.data[mini_child-1],self.data[father-1]\n",
    "                        father=mini_child\n",
    "                        child=father*2\n",
    "                    else:\n",
    "                        setting=False\n",
    "                else:\n",
    "                    setting=False\n",
    "        return data\n",
    "    \n",
    "#the first method: online gradient ascent\n",
    "def online_gradient_ascent(problems,batch=50):\n",
    "            m=Submodular_QP.constraints.shape[0]\n",
    "            n=Submodular_QP.constraints.shape[1]\n",
    "            T=len(problems)\n",
    "            outcome=[0]*T\n",
    "            point=np.zeros((n,1))\n",
    "            #setting the projection QP as 1/2x^{T}Px+q^{T}x s.t Gx \\\\\\\\le g, Cx=c\n",
    "            G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "            g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "            P=cvxopt.matrix(2*np.eye(n))\n",
    "            # we use the priority queue to record the delay information\n",
    "            Q=Priority()\n",
    "            for i in range(T):\n",
    "                outcome[i]=problems[i].exact_value_oracle(point)\n",
    "                gradient=sum(problems[i].stochastic_gradient_oracle(point) for j in range(batch))/batch\n",
    "                Q.insert(problems[i].delay,gradient)\n",
    "                Q.minus_one()\n",
    "                while len(Q)>0 and Q.show().delay==0:\n",
    "                    point+=Q.pop().gradient/math.sqrt(T)\n",
    "                q=cvxopt.matrix(-2*point)\n",
    "                sol=cvxopt.solvers.qp(P,q,G,g)\n",
    "                point=np.array(sol['x'])\n",
    "                point=point.reshape(n,1)\n",
    "            return outcome\n",
    "        \n",
    "#the second method:boosting gradient ascent\n",
    "def boosting_online_gradient_ascent(problems,batch=50):\n",
    "    m=Submodular_QP.constraints.shape[0]\n",
    "    n=Submodular_QP.constraints.shape[1]\n",
    "    T=len(problems)\n",
    "    outcome=[0]*T\n",
    "    point=np.zeros((n,1))\n",
    "    #setting the projection QP as 1/2x^{T}Px+q^{T}x s.t Gx \\\\\\\\le g, Cx=c\n",
    "    G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "    g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "    P=cvxopt.matrix(2*np.eye(n))\n",
    "    # we use the priority queue to record the delay information\\n\",\n",
    "    Q=Priority()\n",
    "    for i in range(T):\n",
    "        outcome[i]=problems[i].exact_value_oracle(point)\n",
    "        gradient=sum(problems[i].stochastic_boosting_gradient_oracle(point) for j in range(batch))/batch\n",
    "        Q.insert(problems[i].delay,gradient)\n",
    "        Q.minus_one()\n",
    "        while len(Q)>0 and Q.show().delay==0:\n",
    "            point+=Q.pop().gradient/math.sqrt(T)\n",
    "        q=cvxopt.matrix(-2*point)\n",
    "        sol=cvxopt.solvers.qp(P,q,G,g)\n",
    "        point=np.array(sol['x'])\n",
    "        point=point.reshape(n,1)\n",
    "    return outcome\n",
    "        \n",
    "#The third method: meta-FW\n",
    "def meta_FW(problems,K=50):\n",
    "            m=Submodular_QP.constraints.shape[0]\n",
    "            n=Submodular_QP.constraints.shape[1]\n",
    "            T=len(problems)\n",
    "            outcome=[0]*T\n",
    "            K_value=[np.zeros((n,1))]*K\n",
    "            #setting the projection QP as 1/2x^{T}Px+q^{T}x s.t Gx \\\\\\\\le g, Cx=c\\n\",\n",
    "            G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "            g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "            P=cvxopt.matrix(2*np.eye(n))\n",
    "            # we use the priority queue to record the delay information\\n\",\n",
    "            Q=[Priority() for i in range(K)]\n",
    "            for i in range(T):\n",
    "                point=sum(K_value)/K\n",
    "                outcome[i]=problems[i].exact_value_oracle(point)\n",
    "                for j in range(K):\n",
    "                    gradient=problems[i].stochastic_gradient_oracle(sum(K_value[:(j+1)])/K)\n",
    "                    Q[j].insert(problems[i].delay,gradient)\n",
    "                    Q[j].minus_one()\n",
    "                    while len(Q[j])>0 and Q[j].show().delay==0:\n",
    "                        K_value[j]+=Q[j].pop().gradient/math.sqrt(T)\n",
    "                    q=cvxopt.matrix(-2*K_value[j])\n",
    "                    sol=cvxopt.solvers.qp(P,q,G,g)\n",
    "                    K_value[j]=np.array(sol['x'])\n",
    "                    K_value[j]=K_value[j].reshape(n,1)\n",
    "            return outcome\n",
    "#the final method: meta-FW-VR\n",
    "def meta_FW_VR(problems,K=50):\n",
    "            m=Submodular_QP.constraints.shape[0]\n",
    "            n=Submodular_QP.constraints.shape[1]\n",
    "            T=len(problems)\n",
    "            outcome=[0]*T\n",
    "            K_value=[np.zeros((n,1))]*K\n",
    "            #setting the projection QP as 1/2x^{T}Px+q^{T}x s.t Gx \\\\\\\\le g, Cx=c\\n\",\n",
    "            G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "            g=cvxopt.matrix(np.concatenate((np.ones((m,1)),np.ones((n,1)),np.zeros((n,1))),axis=0))\n",
    "            P=cvxopt.matrix(2*np.eye(n))\n",
    "            # we use the priority queue to record the delay information\\n\",\n",
    "            Q=[Priority() for i in range(K)]\n",
    "            for i in range(T):\n",
    "                point=sum(K_value)/K\n",
    "                outcome[i]=problems[i].exact_value_oracle(point)\n",
    "                d_t=np.zeros((n,1))\n",
    "                for j in range(K):\n",
    "                    rho=2.2/(j+4)**(2/3)\n",
    "                    gradient=problems[i].stochastic_gradient_oracle(sum(K_value[:(j+1)])/K)\n",
    "                    Q[j].insert(problems[i].delay,gradient)\n",
    "                    Q[j].minus_one()\n",
    "                    gradient_mid=np.zeros((n,1))\n",
    "                    while len(Q[j])>0 and Q[j].show().delay==0:\n",
    "                        gradient_mid+=Q[j].pop().gradient/math.sqrt(T)\n",
    "                    d_t=(1-rho)*(d_t)+rho*gradient_mid\n",
    "                    q=cvxopt.matrix(-2*(K_value[j]+d_t))\n",
    "                    sol=cvxopt.solvers.qp(P,q,G,g)\n",
    "                    K_value[j]=np.array(sol['x'])\n",
    "                    K_value[j]=K_value[j].reshape(n,1)\n",
    "            return outcome\n",
    "def optimal_T(problems):\n",
    "    T=len(problems)\n",
    "    m=Submodular_QP.constraints.shape[0]\n",
    "    n=Submodular_QP.constraints.shape[1]\n",
    "    outcome=[0]*T\n",
    "    #setting the projection QP as 1/2x^{T}Px+q^{T}x s.t Gx \\\\\\\\le g, Cx=c\\\n",
    "    G=cvxopt.matrix(np.concatenate((Submodular_QP.constraints,np.eye(n),-np.eye(n)),axis=0))\n",
    "    g=cvxopt.matrix(np.concatenate((np.ones((m+n,1)),np.zeros((n,1))),axis=0))\n",
    "    P=cvxopt.matrix(2*np.eye(n))\n",
    "    for i in range(T):\n",
    "        point=np.zeros((n,1))\n",
    "        for j in range(100): \n",
    "            gradient=sum(sum(problems[k].stochastic_boosting_gradient_oracle(point) for k in range(i+1)) for z in range(50))/50\n",
    "            point+=gradient/math.sqrt(j+1)\n",
    "            q=cvxopt.matrix(-2*point)\n",
    "            sol=cvxopt.solvers.qp(P,q,G,g)\n",
    "            point=np.array(sol['x'])\n",
    "            point=point.reshape(n,1)\n",
    "        outcome[i]=sum(problems[k].exact_value_oracle(point) for k in range(i+1))\n",
    "    return outcome   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
